



# 19.监督式学习和线性回归

接下来学习通过实装线性回归而进行的监督式学习和预测模型化。

前面探索性分析的学习过程中，并没有涉及到模型化的问题。

下面我们将制成预测住宅市场价格的线性回归模型。

总而言之，就是通过利用目标变量和其以外的变量的关系预测目标变量。

线性回归可以通过很多的手法来转变成监督式机械学习算法的单纯模型。

简而言之，就是符合观测数据的直线。

**首先，会说明监督是学习和线性回归。接着在学习线性回归的必要概念、独立变量和从属变量、
超参数、损失函数和误差函数、随机梯度下降(SGD)等概念**。

学习模型化，使用和之前相同的数据集。

所以我们将要学习的内容如下：
* 监督式学习和线性回归
* 独立变量和从属变量
* 超参数
* 损失函数和误差函数
* 单变量线性回归算法的实装
* 随机梯度下降发的计算
* 使用线性回归的住宅价格模型化

机械学习，如同其字面意思，在没有通过编程的情况下使计算机系统自己进行学习的能力。

其中的监督式学习，是机械学习中最常用的种类之一。

监督式学习是提前设定好学习课题后，通过已知的输入数据与输出数据之间的对应关系生成一个函数，
并将输入映射到合适的输出来解除课题(例如分类)。

监督式学习由多个算法构成。

这些算法，首先需要将输入与其所对应的输出进行解析，然后找寻(学习)企之间的相关性。

最后利用所学习的相关性，对任意未知数据集的输出进行预测。

为了对监督式学习与无监督学习的区别有所了解，可以认为其分别为基于不同的输出入环境的模型化方法。

**监督式学习是计算机系统中所有的输入数据群的标签的信息都是通过监督者给予的**。

而**无监督式学习则是使用的没有任何标签信息的输入数据**。

举例说明一下，假如有一百万张猫和狗的照片。

监督式学习会附带输入数据的标签信息，因此会告诉计算机每张照片所对应的是猫还是狗。

假如每张照片都附带20个特征信息。

我们将照片附加标签的目的，是让计算机系统可以判断出一张照片是猫还是狗，
因此在解析新的照片的20个特征后，计算机可以基于目前为止的学习对其进行判断(预测)。

与之不同，无监督学习是没有表明是猫还是狗的标签，只有100万张照片信息。

算法是，没有监督者的附加信息，独立对数据的特征进行解析，再对其进行聚类分析。

聚类分析结束后，将新照片输入无监督学习算法后，计算机系统将返回该照片属于哪个聚类。

不管哪种方式的学习，都是在系统中设定好单纯或复杂的决定算法。

**唯一的差别就是最开始是是否有监督者赋予的信息**。

下面是监督式学习和无监督学习方法组成的概要。

![](https://github.com/Ghj1314xxx/Numpy/blob/master/Images/learning.png)

正如上图所示，监督式学习分位分类和回归两类。

分类模型是对随机的预测，比如前面所给出的分类问题。

用来实现分类的方法，**支持向量机(SVM)、随机森林、k最近邻法(KNN)等**分类算法的训练都是十分必要的。

一般的，分类指用来将数据分类的算法。

目标变量是分类数据的情况下，可以使用分类方法。

但是对于连续的目标变量的情况下，想要预测的并不是分类的数值，所以要使用回归模型。

互相一下之前使用的波士顿市的住宅价格数据集。

前面学习的目标是为了了解数据的分布、基本统计量和数据之间的相关性，我们队数据集的特征值进行了统计性分析。

然而我们最终想要知道的是，各特征对于住宅价格有着怎样的影响。

某一特征与价格产生的是正面影响还是负面影响，或者说没有什么影响？

特征x与住宅价格A之间是否有着潜在的关系，这个关系是强是弱？

若想要对这些问题进行解答，那么需要构建可以通过给予特征预测住宅价格的模型。

最终是为了给予模型新的特征数据，期待其能够生成作为输出变量的连续值。

![](https://github.com/Ghj1314xxx/Numpy/blob/master/Images/workflow1.jpg)

如同上面流程图，但是在讲数据输入到模型前，我们需要率先对数据进行预处理。

在这个阶段，我们会对数据进行清扫(cleaning)，对缺失值进行处理，将需要的特征提炼出来。

预处理完成后，在数据分为两部分，分别为训练用数据和测试用数据，以便对模型的精准度进行测评。

数据的检验，需要用到一个十分重要的概念，叫做**过拟合**(overfitting)。

过拟合，简而言之是指过于紧密或精确地匹配特定数据集，以致于无法拟合其他数据或预测未来的观察结果的现象。

也就是说，如果对于未知数据，模型具有较差的延展性从而无法正确的得出结果，导致模型无法被一般使用。

为了防止出现过拟合的情况，我们将数据分文训练数据、检验数据(强烈推荐需要)和测试数据三部分。

训练数据，就是算法在最初重复学习的参数，为了使构建的模型误差最小而使用。

检验数据，是用来帮助多数算法调整其超参数所使用的数据。对于算法具有多个参数的情况下是十分必要的。

测试数据，顾名思义是用来测试评价模型精度的数据。

总而言之，我们所制成的算法，通过训练数据进行训练学习，再通过检验数据对其参数和算法进行重复的细微的调整，
在解析最后阶段队已经调整的算法使用测试数据对其精度进行检查。

与过拟合相对应的，同样存在一个概念叫做**欠拟合**(underfitting)。

它是指相较于数据而言，模型参数过少或者模型结构过于简单，以至于无法捕捉到数据中的规律的现象。

发生欠拟合时，模型的偏差大二方差小。

下面我们通过图片来了解过拟合、欠拟合和最适情况。

![](https://github.com/Ghj1314xxx/Numpy/blob/master/Images/overfitting.jpeg)

通过图片我们很容易了解，图一中欠拟合的情况下，数据的形状与其得到的回归曲线并不相符合，这样的模型无法用来分析数据特征。

第三幅图中所对应的是过拟合的情况，该情况下得到的回归曲线与数据集过于拟合，无法正确的捕捉到数据特征。

图二是最适情况下的图像，分布的特征与其所得到的曲线十分契合。

我们可以期待该情况下使用剩余数据集部分进行精度测试时可以得到一个十分高的指标值。




