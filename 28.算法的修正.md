



# 28.算法的修正

对于k平均法的单边两个动作的方法已经有所了解了（其实并没有），

现在将开始多变量的实装，也就是更现实的数据集中进行操作。

本节使用的数据集，是**UCI Machine Learning Repository**。

(https://archive.ics.uci.edu/ml/datasets/wholesale%2Bcustomers)。

所以包含了顾客情报。

有下面8个特征的440个顾客的数据。

下面的列表中，前六个对应的是和商品年间支出之间的关系，

第七个特征是这个商品的购买路径，第八个特征表示地域。

* FRESH 
* MILK
* GROCERY
* FROZEN
* DETERGENTS_PAPER
* DELICATESSEN
* CHANNEL
* REGION

首先，通过下载数据集并通过Numpy数组读取出来。

```python
from numpy import genfromtxt
wholesales_data = genfromtxt('Wholesale customers data.csv',
delimiter=',', skip_header=1)

print(wholesales_data[:5])
```
    [[2.0000e+00 3.0000e+00 1.2669e+04 9.6560e+03 7.5610e+03 2.1400e+02
      2.6740e+03 1.3380e+03]
     [2.0000e+00 3.0000e+00 7.0570e+03 9.8100e+03 9.5680e+03 1.7620e+03
      3.2930e+03 1.7760e+03]
     [2.0000e+00 3.0000e+00 6.3530e+03 8.8080e+03 7.6840e+03 2.4050e+03
      3.5160e+03 7.8440e+03]
     [1.0000e+00 3.0000e+00 1.3265e+04 1.1960e+03 4.2210e+03 6.4040e+03
      5.0700e+02 1.7880e+03]
     [2.0000e+00 3.0000e+00 2.2615e+04 5.4100e+03 7.1980e+03 3.9150e+03
      1.7770e+03 5.1850e+03]]
      
通过`shape`确认行数和变量数。

```python
wholesales_data.shape
```
--->(440, 8)

这个数据集有440个记录数和分别具有的8个变量。

现在这个阶段，可以开始对数据集进行正规化。

```python
wholesales_data_norm = wholesales_data / np.linalg.norm(wholesales_data)

print(wholesales_data_norm[:5])
```
    [[3.83209141e-06 5.74813712e-06 2.42743830e-02 1.85013373e-02
      1.44872216e-02 4.10033781e-04 5.12350622e-03 2.56366915e-03]
     [3.83209141e-06 5.74813712e-06 1.35215345e-02 1.87964084e-02
      1.83327253e-02 3.37607253e-03 6.30953851e-03 3.40289717e-03]
     [3.83209141e-06 5.74813712e-06 1.21726384e-02 1.68765306e-02
      1.47228952e-02 4.60808992e-03 6.73681670e-03 1.50294625e-02]
     [1.91604571e-06 5.74813712e-06 2.54163463e-02 2.29159066e-03
      8.08762892e-03 1.22703567e-02 9.71435173e-04 3.42588972e-03]
     [3.83209141e-06 5.74813712e-06 4.33313736e-02 1.03658073e-02
      1.37916970e-02 7.50131894e-03 3.40481322e-03 9.93469698e-03]]
      
```python
import pandas as pd
df = pd.DataFrame(wholesales_data_norm, columns=['Channel', 'Region', 'Fresh', 'Milk', 'Grocery', 'Frozen', 'Detergents_paper', 'Delicassen'])

df.head()
```
![](https://github.com/Ghj1314xxx/Numpy/blob/master/Images/ws.PNG)

通过数据集，可于做出更利于观察的散布图矩阵。

```python
fig = ff.create_scatterplotmatrix(df, diag='histogram', size=7, height=1200, width=1200)
plot(fig)
```
![](https://github.com/Ghj1314xxx/Numpy/blob/master/Images/sca.png)

接下来通过下列代码对特征之间的相关性进行查询。

```python
df.corr()
```
![](https://github.com/Ghj1314xxx/Numpy/blob/master/Images/corr.png)

接下来还可以利用表内信息，将数据表示为`seabor`的热点图。

```python
import seaborn as sns; sns.set()

ax = sns.heatmap(df.corr(), annot=True)
```
![](https://github.com/Ghj1314xxx/Numpy/blob/master/Images/htm.png)

特点的特征之间，比如`Grocery`和`Detergents_Paper`之间有个较强的相关性就比较容易被观察到。

下面的三个特征，`Grocery`,`Detergents_Paper`和`Milk`可以使用下面展示的代码这样，将其图示化。

```python
# Create data for the plotly
trace1 = go.Scatter(
    # Extracting data based on label
    x = df[df['labels'] == 0]['Grocery'],
    y = df[df['labels'] == 0]['Detergents_Paper'],
    mode = 'markers',
    name = 'clust_1',
    marker = dict(
        size = 12,
        line = dict(
            color = 'rgba(217, 217, 217, 0.14)',
            width = 0.5
        ),
        opacity = 0.8
    )
)

# Layout settings
layout = go.Layout(
    scene = dict(
        xaxis = dict(
            title = 'Grocery'),
        yaxis = dict(
            title = 'Dertergents_Paper'),
    )
)

data = [trace1]

fig = go.Figure(data=data, layout=layout)

plot(fig)
```




