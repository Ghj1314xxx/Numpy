



    固有值是固有向量的系数，定义上，如果一个非零向量，在进行了线性变换后，仍然与原向量在同一直线上，即
  只对原函数进行了标量倍变化，则称该向量为固有向量。固有向量在线性变换中只进行伸缩或反转，相当于在原向量
  基础上乘以标量(实数或复数)，且该标量被成为固有值。固有值和固有向量在数学上表现为
                                        Av = av
    在机械学习的算法中，经常需要操作高次元数。这其中最大的问题并不是巨大的次元，而是本身的算法是否适合其
  对应的次元，以及性能如何之类的问题。比方说，主次元分析(PAC:principal component analysis)，便是找出操作
  次元中最有价值的线性结合。
    下面的例子，会使用到新的scikit-learn库来济宁数据组合的读取，PCA的实行等。scikit-learn是python中一个
  免费的机械学习库，以Scipy为基础制作而成，集合了许多可以进行类分类、回归、集群分析、SVM(支持向量机)、
  DBSCAN(聚类算法)、k平均法等机械学习算法中很多用的函数和模块。
    并且，scikit-learn和Numpy、Scipy、pandas之间的互换性非常优秀，sklearn库的数据构造中也可以使用Numpy
  数组。甚至可以使用sklearn_pandas将scikit-learn的管道(pipeline)输出的值转化为pandas的数据帧(dataframe)。
  而且，scikit-learn在auto_ml和auto-sklearn库的帮助下，可以支持机械学习算法的自动化。
    为了了解PCA中固有值和固有向量的使用方法和重要性，下面将通过实践练习。下面的代码，将先在Numpy中进行计算，
  将结果在组合sklearn地方法进行比较验证。这里使用了sklearn中的datasets库中关于乳腺癌的dataset。首先需要对
  必要的库和dataset进行宣告(import)，然后进行标准化。标准化极为重要，特别是对于类似scikit-learn等机械学习
  算法的推定器来说是必要环境。这个例子是使用StandardScaler()函数将特征进行标准化。这里的主要目的是将特征
  转化成标准的正规分布(平均为0，分散为1)数据。fit_transform()函数将原数据变化为平均为0，标准偏差为1的分布
  形态。
      1) import numpy as np
         from sklearn import decomposition, datasets
         from sklearn.preprocessing import StandardScaler
         data = datasets.load_breast_cancer()
         cancer = data.data
         cancer = StandardScaler().fit_transform(cancer)
         cancer.shape  ------  (569, 30)
    
    对上面数据的形状进行确认，知道其为569行30列。下面将对标准化前后数据进行比较，从而了解原数组是如何变换。
  下面我们从乳腺癌数据中抽出一列进行变换。
      2) before_transformation = data.data
         before_transformation[:10, :1]  ------  array([[17.99],
                                                        [20.57],
                                                        [19.69],
                                                        [11.42],
                                                        [20.29],
                                                        [12.45],                                              
                                                        [18.25],
                                                        [13.71],
                                                        [13.  ],
                                                        [12.46]])
    
         cancer[:10, :1]  ------  array([[ 1.09706398],
                                         [ 1.82982061],
                                         [ 1.57988811],
                                         [-0.76890929],
                                         [ 1.75029663],
                                         [-0.47637467],
                                         [ 1.17090767],
                                         [-0.11851678],
                                         [-0.32016686],
                                         [-0.47353452]])
    
    标准化计算式如下，
                        Z = ( x - u ) / o
                       注： x      原值
                            u      平均分布
                            o      标准偏差
                            Z      标准化后的值
    
    数据变换后，为了使用np.linalg.eig()计算固有值和固有向量，因此通过下面代码进行共分散矩阵的计算，
  接着将其分解。
      3) covariance_matrix = np.cov(cancer, rowvar=False)
         covariance_matrix.shape  ------  (30, 30)
         
         eig_val_cov, eig_vec_cov = np.linalg.eig(covariance_matrix)
         eig_pairs = [(np.abs(eig_val_cov[i]), eig_vec_cov[:,i] for i in range(len(eig_val_cov))]
         
    上面的代码，是计算由全部特征得到的共分散矩阵。dataset由30个特征，所以共分散矩阵是一个形状为(30,30)
  的二次元数组。下面将固有值降序排序。
      4) sorted_pairs = eig_pairs.sort(key=lambda x: x[0], reverse=True)
         for i in eig_pairs:
             print(i[0])  ------  13.30499079437456
                                  5.701374603726145
                                  2.822910155006232
                                  1.9841275177301991
                                  1.6516332423301192
                                  1.2094822398029708
                                  0.676408881700905
                                  0.47745625468950725
                                  0.4176287821078162
                                  0.35131087488173346
                                  0.29443315349116345
                                  0.2616211613661206
                                  0.24178242132831365
                                  0.1572861492175932
                                  0.09430069560105592
                                  0.08000340447737715
                                  0.059503613530432514
                                  0.05271142221014794
                                  0.049564700212981684
                                  0.031214260553066562
                                  0.030025663090428544
                                  0.027487711338904174
                                  0.02438369135459101
                                  0.018086793984305502
                                  0.015508527134418594
                                  0.008192037117607045
                                  0.006912612579184395
                                  0.0015921360011974513
                                  0.0007501214127185336
                                  0.00013327905666396465
                                  
    为了减少次元作业空间决定要除去的固有向量，所以将固有值降序排列是有必要的。上述排列一列表形式表示，
  数值较大的固有值只有最初的两个固有向量，但是包含的关于数据分布的情报是最多的。因此，为了得到低次元
  作业空间，将其他数据除去。
      5) matrix_w = np.hstack((eig_pairs[0][1].reshape(30,1), eig_pairs[1][1].reshape(30,1)))
         matrix_w.shape
         transformed = matrix_w.T.dot(cancer.T)
         transformed = transformed.T
         transformed[0]  ------  array([9.19283683, 1.94858307])
         
         transformed.shape  ------  (569, 2)
         
    上面的代码，是将最初的两个固有向量进行水平合并。这个矩阵和元数据的矩阵相乘，将元数据在新的次元数的
  部分空间上映射。最后的数据由(569，30)变换为(569，2)，但是也意味着通过PCA处理将其中的28个特征消除了。
       6) import numpy as np
          from sklearn import decomposition
          from sklearn import datasets
          from sklearn.preprocessing import StandardScaler
          pca = decomposition.PCA(n_components=2)
          x_std = StandardScaler().fit_transform(cancer)
          pca.fit_transform(x_std)[0]  ------  array([9.19283683, 1.94858307])
          
    在其他库中，也进行同样演算的组合函数。scikit-learn中，可以在机械学习算法中使用的组合方法和函数有
  很多。上面的算法适合之前进行同样的PCA，但是只需要3行代码就可以搞定。这个例子的主要目的还是用来展示
  固有值和固有向量的重要性，后面有机会也会介绍通过Numpy进行PCA的简单办法。
    
    
    
    
    
    
    
