


# 基本统计量的查找

接下来学习的是数据集的基本统计量的计算，这也是向统计分析迈出的第一步。

由于Numpy库中内置的统计函数较为有限，所以我们引入Scipy库进行使用。

首先需要说明分析的流程。

尽管所有的特征列和标签列都是数值，但是**CHAS(Charles River dummy variable)
查尔斯河虚拟变量取二进制数字，如果是大片土地则为1，否则为0**。

事实上这是将其编码为分类数据的意思。

在分析数据集的时候，将列的”分类“和”数据“分离开是可行的。

想要一起解析的情况下，需要将一方转换成另一方。

若想要将分类值转化成数值，需要将各分类分别转换成一个独立的数值，这个手法叫做编码。

相反的，将数据分箱后也可以转换成分类值。

刚刚开始接触分析，需要将特征一一探索。

统计学中，将这种手法叫做**单变量解析**。

单变量解析的目的主要是**记述特征**。

这里先将计算最小值、最大值、范围、百分比、平均值和分散，然后将其以直方图图示，再分析各个特征的分布。

然后我们会触及到偏度和峰度的概念，进而了解Trim的重要性。

单变量解析结束后，再进行两个特征同时解析的二变量解析。

所以，我们需要看一下两个特征集合间的关系。

```python
import numpy as np
from sklearn.datasets import load_boston
dataset = load_boston()
samples, label, feature_names = dataset.data, dataset.target, dataset.feature_names

np.set_printoptions(suppress=True, linewidth=125)
minimums = np.round(np.amin(samples, axis=0), decimals=1)
maximums = np.round(np.amax(samples, axis=0), decimals=1)
range_column = np.round(np.ptp(samples, axis=0), decimals=1)
mean = np.round(np.mean(samples, axis=0), decimals=1)
median = np.round(np.median(samples, axis=0), decimals=1)
variance = np.round(np.var(samples, axis=0), decimals=1)
tenth_parcentile = np.round(np.percentile(samples, 10, axis=0), decimals=1)
ninety_percentile = np.round(np.percentile(samples, 90, axis=0), decimals=1)

range_column
```
>array([ 89. , 100. ,  27.3,   1. ,   0.5,   5.2,  97.1,  11. ,  23. , 524. ,   9.4, 396.6,  36.2])

```python
Basic_Statistics = np.vstack((minimums, maximums, range_column, mean, median, variance, tenth_percentile, ninety_percentile))
Basic_Statistics
```
>array([[    0. ,     0. ,     0.5,     0. ,     0.4,     3.6,     2.9,     1.1,     1. ,   187. ,    12.6,     0.3,
            1.7],
       [   89. ,   100. ,    27.7,     1. ,     0.9,     8.8,   100. ,    12.1,    24. ,   711. ,    22. ,   396.9,
           38. ],
       [   89. ,   100. ,    27.3,     1. ,     0.5,     5.2,    97.1,    11. ,    23. ,   524. ,     9.4,   396.6,
           36.2],
       [    3.6,    11.4,    11.1,     0.1,     0.6,     6.3,    68.6,     3.8,     9.5,   408.2,    18.5,   356.7,
           12.7],
       [    0.3,     0. ,     9.7,     0. ,     0.5,     6.2,    77.5,     3.2,     5. ,   330. ,    19. ,   391.4,
           11.4],
       [   73.8,   542.9,    47. ,     0.1,     0. ,     0.5,   790.8,     4.4,    75.7, 28348.6,     4.7,  8318.3,
           50.9],
       [   10.8,    42.5,    19.6,     0. ,     0.7,     7.2,    98.8,     6.8,    24. ,   666. ,    20.9,   396.9,
           23. ],
       [   10.8,    42.5,    19.6,     0. ,     0.7,     7.2,    98.8,     6.8,    24. ,   666. ,    20.9,   396.9,
           23. ]])

上面的代码中，使用`set_printoptions()`函数设定输出的设置，随后将小数点以下四舍五入减少位数，最后将所有的列都收录在画面中。

对于基本统计量的计算，我们可以使用Numpy内置的`amin()`,`amax()`,`mean()`,`median()`,`var()`,`percentile()`,`ptp()`等函数。

因为每个列表示一个特征，因此我们所有的计算都需要对每个列进行。

得到结果的数组还是有些复杂难以将列与统计量相对应。

```python
stat_labels = ['minm','maxm','rang','mean','medi','vari','10%t','90%t'] 

print("       F1    F2    F3    F4    F5    F6    F7    F8    F9    F10    F11    F12    F13")
for stat_labels, row in zip(stat_labels, Basic_Statistics):
    print('%s [%s]'%(stat_labels, ''.join('%07s'%i for i in row)))
```
>           F1     F2     F3     F4     F5     F6     F7     F8     F9    F10    F11    F12    F13
>minm [    0.0    0.0    0.5    0.0    0.4    3.6    2.9    1.1    1.0  187.0   12.6    0.3    1.7]
>maxm [   89.0  100.0   27.7    1.0    0.9    8.8  100.0   12.1   24.0  711.0   22.0  396.9   38.0]
>rang [   89.0  100.0   27.3    1.0    0.5    5.2   97.1   11.0   23.0  524.0    9.4  396.6   36.2]
>mean [    3.6   11.4   11.1    0.1    0.6    6.3   68.6    3.8    9.5  408.2   18.5  356.7   12.7]
>medi [    0.3    0.0    9.7    0.0    0.5    6.2   77.5    3.2    5.0  330.0   19.0  391.4   11.4]
>vari [   73.8  542.9   47.0    0.1    0.0    0.5  790.8    4.4   75.728348.6    4.7 8318.3   50.9]
>10%t [   10.8   42.5   19.6    0.0    0.7    7.2   98.8    6.8   24.0  666.0   20.9  396.9   23.0]
>90%t [   10.8   42.5   19.6    0.0    0.7    7.2   98.8    6.8   24.0  666.0   20.9  396.9   23.0]

想要更容易理解的输出Numpy数组的情况下，可以使用`zip()`函数给行加上标签(label)，使得列标签在数列上表示出来。

Scipy中计算基本统计量的统计函数还有很多可以被使用。

Scipy中的`describe()`函数可以返回多组数组的记述统计量。

使用`describe()`函数，将观测数量、最小、最大、平均、分散、偏度、峰度在一个函数中求出。

```python
from scipy import stats
arr = stats.describe(samples, axis=0)
arr
```
>DescribeResult(nobs=506, minmax=(array([  0.00632,   0.     ,   0.46   ,   0.     ,   0.385  ,   3.561  ,   2.9    ,   1.1296 ,   1.     , 187.     ,
        12.6    ,   0.32   ,   1.73   ]), array([ 88.9762, 100.    ,  27.74  ,   1.    ,   0.871 ,   8.78  , 100.    ,  12.1265,  24.    , 711.    ,  22.    ,
       396.9   ,  37.97  ])), mean=array([  3.61352356,  11.36363636,  11.13677866,   0.06916996,   0.55469506,   6.28463439,  68.57490119,   3.79504269,
         9.54940711, 408.23715415,  18.4555336 , 356.67403162,  12.65306324]), variance=array([   73.9865782 ,   543.93681368,    47.06444247,     0.06451297,     0.01342764,     0.49367085,   792.35839851,
           4.43401514,    75.81636598, 28404.75948812,     4.68698912,  8334.75226292,    50.99475951]), skewness=array([ 5.20765239,  2.21906306,  0.29414628,  3.39579929,  0.72714416,  0.40241467, -0.59718559,  1.00877876,  1.00183349,
        0.66796827, -0.79994453, -2.88179835,  0.90377074]), kurtosis=array([36.75278626,  3.97994877, -1.23321847,  9.53145284, -0.07586422,  1.86102697, -0.97001393,  0.47129857, -0.8705205 ,
       -1.14298488, -0.29411638,  7.14376929,  0.47654476]))

下面的代码将分别计算基本统计量并最后合并到输出矩阵。

```python
minimum = arr.minmax[0]
maximum = arr.minmax[1]
mean = arr.mean
median = np.round(np.median(samples, axis=0), decimals=1)
variance = arr.variance
tenth_percentile = stats.scoreatpercentile(samples, per=10, axis=0)
ninty_percentile = stats.scoreatpercentile(samples, per=90, axis=0)
rng = stats.iqr(samples, rng=(20, 80), axis=0)
np.set_printoptions(suppress=True, linwidth=125)
Basic_Statistics1 = np.round(np.vstack((minimum, maximum, rng, mean, median, variance, tenth_percentile, ninety_percentile)), decimals=1)
Basic_Statistics1.shape
```
>(8, 13)

```python
stat_labels1 = ['minm', 'maxm', 'rang', 'mean', 'medi', 'vari', '10%t', '90%t']

np.set_printoptions(suppress=True, linewidth=125)
print("       F1    F2    F3    F4    F5    F6    F7    F8    F9    F10    F11    F12    F13")
for stat_labels1, row1 in zip(stat_labels1, Basic_Statistics1):
    print('%s [%s]'%(stat_labels1, ''.join('%07s'%i for i in row1)))
```
>       F1    F2    F3    F4    F5    F6    F7    F8    F9    F10    F11    F12    F13
>minm [    0.0    0.0    0.5    0.0    0.4    3.6    2.9    1.1    1.0  187.0   12.6    0.3    1.7]
>maxm [   89.0  100.0   27.7    1.0    0.9    8.8  100.0   12.1   24.0  711.0   22.0  396.9   38.0]
>rang [    5.5   20.0   13.7    0.0    0.2    0.9   57.8    3.7   20.0  393.0    3.6   32.6   11.8]
>mean [    3.6   11.4   11.1    0.1    0.6    6.3   68.6    3.8    9.5  408.2   18.5  356.7   12.7]
>medi [    0.3    0.0    9.7    0.0    0.5    6.2   77.5    3.2    5.0  330.0   19.0  391.4   11.4]
>vari [   74.0  543.9   47.1    0.1    0.0    0.5  792.4    4.4   75.828404.8    4.7 8334.8   51.0]
>10%t [    0.0    0.0    2.9    0.0    0.4    5.6   27.0    1.6    3.0  233.0   14.8  290.3    4.7]
>90%t [   10.8   42.5   19.6    0.0    0.7    7.2   98.8    6.8   24.0  666.0   20.9  396.9   23.0]

和Numpy不同，求范围可以使用`iqr()`函数。

这个函数是计算数据指定的轴和范围(通过rng参数指定)的四分位范围。

默认rng=(25, 75)，表示函数将计算75%和25%的差。

和函数`numpy.ptp()`返回相同的结果，若指定`rng(0, 100)`将计算给予的所有的数据的范围。

上面的代码中使用了`stat.scoreatpercentile()`函数，和`numpy.percentile()`函数相同，用于求特征中10%和90%的值。

观察结果，可以发现大部分的特征的分散都非常的高。

这是表示存在很多特征分布在两端的较为极端的值。

从上面的结果中，可以发现大多数数据中平均值都大于中间值，换句话说就是特征的分布较为偏右。




