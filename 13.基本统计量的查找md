


# 基本统计量的查找

接下来学习的是数据集的基本统计量的计算，这也是向统计分析迈出的第一步。

由于Numpy库中内置的统计函数较为有限，所以我们引入Scipy库进行使用。

首先需要说明分析的流程。

尽管所有的特征列和标签列都是数值，但是**CHAS(Charles River dummy variable)
查尔斯河虚拟变量取二进制数字，如果是大片土地则为1，否则为0**。

事实上这是将其编码为分类数据的意思。

在分析数据集的时候，将列的”分类“和”数据“分离开是可行的。

想要一起解析的情况下，需要将一方转换成另一方。

若想要将分类值转化成数值，需要将各分类分别转换成一个独立的数值，这个手法叫做编码。

相反的，将数据分箱后也可以转换成分类值。

刚刚开始接触分析，需要将特征一一探索。

统计学中，将这种手法叫做**单变量解析**。

单变量解析的目的主要是**记述特征**。

这里先将计算最小值、最大值、范围、百分比、平均值和分散，然后将其以直方图图示，再分析各个特征的分布。

然后我们会触及到偏度和峰度的概念，进而了解Trim的重要性。

单变量解析结束后，再进行两个特征同时解析的二变量解析。

所以，我们需要看一下两个特征集合间的关系。

```python
import numpy as np
from sklearn.datasets import load_boston
dataset = load_boston()
samples, label, feature_names = dataset.data, dataset.target, dataset.feature_names

np.set_printoptions(suppress=True, linewidth=125)
minimums = np.round(np.amin(samples, axis=0), decimals=1)
maximums = np.round(np.amax(samples, axis=0), decimals=1)
range_column = np.round(np.ptp(samples, axis=0), decimals=1)
mean = np.round(np.mean(samples, axis=0), decimals=1)
median = np.round(np.median(samples, axis=0), decimals=1)
variance = np.round(np.var(samples, axis=0), decimals=1)
tenth_parcentile = np.round(np.percentile(samples, 10, axis=0), decimals=1)
tenth_percentile = np.round(np.percentile(samples, 90, axis=0), decimals=1)

range_column
```
>array([ 89. , 100. ,  27.3,   1. ,   0.5,   5.2,  97.1,  11. ,  23. , 524. ,   9.4, 396.6,  36.2])

```python
Basic_Statistics = np.vstack((minimums, maximums, range_column, mean, median, variance, tenth_percentile, ninety_percentile))
Basic_Statistics
```
>array([[    0. ,     0. ,     0.5,     0. ,     0.4,     3.6,     2.9,     1.1,     1. ,   187. ,    12.6,     0.3,
            1.7],
       [   89. ,   100. ,    27.7,     1. ,     0.9,     8.8,   100. ,    12.1,    24. ,   711. ,    22. ,   396.9,
           38. ],
       [   89. ,   100. ,    27.3,     1. ,     0.5,     5.2,    97.1,    11. ,    23. ,   524. ,     9.4,   396.6,
           36.2],
       [    3.6,    11.4,    11.1,     0.1,     0.6,     6.3,    68.6,     3.8,     9.5,   408.2,    18.5,   356.7,
           12.7],
       [    0.3,     0. ,     9.7,     0. ,     0.5,     6.2,    77.5,     3.2,     5. ,   330. ,    19. ,   391.4,
           11.4],
       [   73.8,   542.9,    47. ,     0.1,     0. ,     0.5,   790.8,     4.4,    75.7, 28348.6,     4.7,  8318.3,
           50.9],
       [   10.8,    42.5,    19.6,     0. ,     0.7,     7.2,    98.8,     6.8,    24. ,   666. ,    20.9,   396.9,
           23. ],
       [   10.8,    42.5,    19.6,     0. ,     0.7,     7.2,    98.8,     6.8,    24. ,   666. ,    20.9,   396.9,
           23. ]])

上面的代码中，使用`set_printoptions()`函数设定输出的设置，随后将小数点以下四舍五入减少位数，最后将所有的列都收录在画面中。

对于基本统计量的计算，我们可以使用Numpy内置的`amin()`,`amax()`,`mean()`,`median()`,`var()`,`percentile()`,`ptp()`等函数。

因为每个列表示一个特征，因此我们所有的计算都需要对每个列进行。

得到结果的数组还是有些复杂难以将列与统计量相对应。

```python
stat_labels = ['minm','maxm','rang','mean','medi','vari','10%t','90%t'] 

print("       F1    F2    F3    F4    F5    F6    F7    F8    F9    F10    F11    F12    F13")
for stat_labels, row in zip(stat_labels, Basic_Statistics):
    print('%s [%s]'%(stat_labels, ''.join('%07s'%i for i in row)))
