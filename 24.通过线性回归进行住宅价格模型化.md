


# 24.通过线性回归进行住宅价格模型化

本节我们还是会使用之前一直在使用的同样的数据集，来进行多变量的线性回归。

和前节不同的是，本节将使用sklearn库来介绍线性回归模型的多种制作方法。

在线性回归模型制作开始前，我们先使用`trimboth()`函数对数据集的两侧进行相同比例的修剪，来去除离群值。

```python
import numpy as np
import pandas as pd
from scipy import stats
from sklearn.linear_model import LinearRegression

from sklearn.datasets import loud_boston
dataset = loud_boston()

samples, label, feature_names = dataset.data, dataset.target, dataset.feature_names

samples_trim = stats.trimboth(samples, 0.1)
label_trim = stats. trimboth(label, 0.1)

print(samples.shape)
print(label.shape)
```
    --->(506, 13)
        (506,)

```python
print(samples_trim.shape)
print(label_trim.shape)
```
    --->(406, 13)
        (406,)
         
从上面的代码部分可以了解到，数据从左后各修剪10%，所以最终各属性和标签列的大小尺寸都从506减少到406.

```python
from sklearn.model_selection import train_test_split
samples_train, samples_test, label_train, label_test = train_test_split(samples_trim, label_trim, test_size=0.2, random_state=0)

print(samples_train.shape)
print(samples_test.shape)
print(label_train.shape)
print(label_test.shape)
```
    --->(324, 13)
        (82, 13)
        (324,)
        (82,)

```python
regressor = LinearRegression()
regressor.fit(samples_train, label_train)
```
    --->LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
   
```python
regressor.coef_
```
    --->array([ 2.46748839e-01,  8.65766738e-02,  9.88939232e-02,  1.35308431e-13,
                4.85333162e+00, -8.39967991e-02,  1.97620277e-02,  2.85396519e-01,
               -5.50556603e-03, -3.73880475e-03,  1.96604482e-01,  4.01607187e-02,
                3.74665639e-01])
            
```python
regressor.intercept_
```
    --->-6.9258743873267505
    
接下来使用`train_test_split()`函数，将数据集分割成训练数据和验证数据。

这个方法是机械学系中常用的手法。

将数据分成两块，首先使用数据对模型进行训练（学习），然后使用剩下的数据对模型进行验证。

使用这个方法的理由，是为了在检验模型的时候减少偏差（bias）。

各个系数用来表示在样本每增加1单位时，预测目标值会发生怎样的变化。

```python
label_pred = regressor.predict(samples_test)

plt.scatter(label_test, label_pred)
plt.xlabel("Prices")
plt.ylabel("Predicted Prices")
plt.title("Prices vs Predicted Prices")
plt.axis("equal")
```
    --->(11.770143369175626, 34.22985663082437, 10.849075090120197, 34.19730798286608)
 ![](https://github.com/Ghj1314xxx/Numpy/blob/master/Images/pvpp.png)
    
从上面的代码部分得到的模型如图。

使用这个模型对对应的数据集进行实行时，将使用到`predict()`函数。

`predict()`函数是将给予数据集输入到模型中实行后，对结果进行返回的函数。

理想的预测是，分布点在直线x=y，也就是角度为45°的线性直线上面。

这是完美的一一对应的预测。

虽然我们的预测并不能说是完美的，但是从分布图上来看，也并没有很坏。

描述模型的精度的两个关键评价指标，我们可以通过下面的方法查询。

```python
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
mse = mean_squared_error(label_test, label_pred)
r2 = r2_score(label_test, label_pred)
print(mse)
print(r2)
```
    --->2.0128846002671437
        0.9162713536078845
        
第一个评价指标是平均二乘误差。

向模型中追加独立变量后，这个值可能会有很大的减少。

第二个评价指标是决定系数（R^2)。

决定系数是用来度量从属变量的偏差中可由独立变量解部分所占的比率。

这个模型中的决定系数是0.91，表示住宅价格的偏差中有91%可以通过这个模型的13个特征进行说明解释。

正如你所见，通过`scikit-learn`中提供的便利的线性回归函数，可以快速图示模型的架构。

另一方面，若只使用Numpy，对于独立的线性回归模型的构建也很简单。

这种场合下，算法的各部分都很容易控制，所以模型的柔软度应该会更高。

------

线性回归是对连续值关系的模型化中最常用的方法之一。

对其的应用在产业界有着很广泛的使用。

从线性回归进行模型化开始说明的原因，并不单单是因为其人气高，
技术相对简单，大部分机械学习的算法的构成要素也基本上全部包含在内也是重要的原因之一。

目前为止对监督式学习与无监督学习进行了学习，并且通过使用波士顿市住宅价格数据集构建了线性回归模型。

超参数、损失函数、梯度下降法等重要的概念也都与所接触。

这里最大的帮助就是通过理解线性回归模型的构建与调整，对其过程的理解提供了充足的知识。

讨论了单变量与多变量新型回归的两个实例。

并且也有了通过Numpy和scikit-learn两种方法使用线性回归的经验。

希望可以在时间充足的情况下，通过本章学习到的内容对其他的数据集进行操作与练习，尝试改变超参数观察其结果有着怎样的变化。

之后，我们会通过卸卖业者的数据集对分类分析的手法进行学习。





